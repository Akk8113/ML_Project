# ğŸ’¡ Wafer Fault Detection â€“ End-to-End ML System

An industrial-grade **Machine Learning** project that automates the detection of faulty semiconductor wafers using sensor data. This project simulates a **real-time QA process** and is fully deployed on the **cloud** with an interactive **web interface**.

---

## ğŸ§¾ Table of Contents

1. [ğŸ“Œ Problem Statement](#-problem-statement)  
2. [ğŸ“Š Dataset Overview](#-dataset-overview)  
3. [ğŸ› ï¸ Technologies Used](#-technologies-used)  
4. [ğŸ” Project Workflow](#-project-workflow)  
5. [ğŸ§  Model Training Pipeline](#-model-training-pipeline)  
6. [ğŸŒ Web App Deployment](#-web-app-deployment)  
7. [ğŸ–¥ï¸ UI Walkthrough](#-ui-walkthrough)  
8. [ğŸ“‚ Project Structure](#-project-structure)  
9. [ğŸ“¥ Installation & Running Instructions](#-installation--running-instructions)  
10. [ğŸš€ Live Demo](#-live-demo)  
11. [ğŸ­ Real-World Application](#-real-world-application)  
12. [ğŸ‘¨â€ğŸ’» Author](#-author)

---

## ğŸ“Œ Problem Statement

Semiconductor wafers can often be defective due to process anomalies. Manual inspection is time-consuming and error-prone.  
The goal is to build a **machine learning system** that can classify wafers as:

- âœ… **Good Wafer**
- âŒ **Bad Wafer**

using their **sensor data** and provide **real-time prediction** via a web app.

---

## ğŸ“Š Dataset Overview

- Collected sensor data from semiconductor manufacturing equipment  
- Each row represents readings from multiple sensors  
- Final label: `Good/Bad` wafer  
- File: `wafer_data.csv`

---

## ğŸ› ï¸ Technologies Used

| Category             | Tools & Frameworks                   |
|----------------------|--------------------------------------|
| Language             | Python                               |
| Libraries            | Pandas, NumPy, Scikit-learn, Matplotlib |
| Model Serialization  | Pickle                               |
| Web Framework        | Flask                                |
| Frontend             | HTML5, CSS3                          |
| IDE & Notebooks      | VS Code, Jupyter Notebook            |
| Deployment           | Render (Cloud Platform)              |

---

## ğŸ” Project Workflow

1. **Data Ingestion**: Load sensor data from `.csv`
2. **EDA & Cleaning**: Explore, visualize, and preprocess data
3. **Feature Engineering**: Handle missing values, scale data
4. **Model Training**: Train classification models, evaluate performance
5. **Pipeline Integration**: Automate transformation + prediction
6. **Flask Web App**: Create web interface for interaction
7. **Cloud Deployment**: Deploy using Render

---

## ğŸ§  Model Training Pipeline

- Implemented using a modular structure:
  - `DataIngestion` â†’ Reads and splits the data
  - `DataTransformation` â†’ Preprocesses features and scales them
  - `ModelTrainer` â†’ Trains and evaluates multiple models

- Best model selected based on **accuracy**, **R2 score**, etc.
- Final model and preprocessor saved as:
  - `artifact/model.pkl`
  - `artifact/preprocessor.pkl`

---

## ğŸŒ Web App Deployment

- Built a **Flask app** (`app.py`) to serve predictions
- Interface allows:
  - Uploading a `.csv` file
  - Manual sensor value input
- Final prediction shown: **Good Wafer / Bad Wafer**
- Hosted using **Render** for 24/7 availability

---

## ğŸ–¥ï¸ UI Walkthrough

- **Homepage**: Input sensor values or upload file  
- **Output**: Displays classification result  
- **Error Handling**: Validates inputs and shows user-friendly errors

---

### ğŸ“‚ Project Structure

```
wafer-fault-detection/
â”‚
â”œâ”€â”€ app.py                    # Flask web server script
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ home.html             # HTML page for user input and output
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ train_pipeline.py     # Full model training pipeline
â”‚   â””â”€â”€ predict_pipeline.py   # Prediction logic using saved model
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ components/           # Data ingestion, transformation, training modules
â”‚
â”œâ”€â”€ artifact/                 # Stores trained model, preprocessor, and raw data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb             # Data exploration & cleaning
â”‚   â””â”€â”€ model_trainer.ipynb   # Model training experimentation
â”‚
â”œâ”€â”€ wafer_data.csv            # Input dataset for training/testing
â”œâ”€â”€ requirements.txt          # Project dependencies
â””â”€â”€ README.md                 # Project documentation
```


2. Create Virtual Environment
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate

3. Install Dependencies
    pip install -r requirements.txt

4. Run the Flask App
    python app.py


ğŸ‘¨â€ğŸ’» Author
Arpit Kakaiya
ğŸ“˜ B.Tech Final Year â€“ Computer Engineering
ğŸ“ India
ğŸ“§ kakaiyaarpit@gmail.com
https://www.linkedin.com/in/arpit-kakaiya-5ab78a1a4/
